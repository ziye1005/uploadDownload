荣誉名称：

研究生一等学业奖学金

研究生两年期间，获得两次研究生一等学业奖学金

本科生学业奖学金

本科生四年共评选三次学业奖学金，获得一次三好学生标兵优秀奖学金、三好学生奖学金、两次一等学业奖学金

数学建模竞赛二等奖



参加2022年第十二届APMCM亚太地区大学生数据建模竞赛，获得二等奖

论文

基于网络编码的协作恢复机制线性可解性研究

 http://www.infocomm-journal.com/txxb/CN/10.11959/j.issn.1000-436x.2021050



项目：

HS效能数据服务系统

总经费2000余万，包含三个子系统（数据采集与预处理、数据存储与分析、数据检索与应用）。采用SpringCloud + Vue.js + HDFS + Hive + Neo4j 框架，将爬虫及整理的多源异构数据存储在HDFS上，通过数据预处理、ETL构建基础数据库，同时将关系数据库转化成图结构，构建非关系型Neo4j知识图谱，可实现数据采集、数据治理、数据应用的完整流程。
本人主要负责：整理武器弹药等八大数据库的数据规范作为本体标签树，与HDFS、Neo4j的数据标签关联对应，支持数据规范的联合查询与管理。支持对一段文本进行实体关系抽取、知识融合后半自动化导入图谱，支持知识图谱的可视化管理、批量导入，支持整个图数据库部分的前后端开发。
目前项目已经完成两次验收、软硬件部署、投入使用、手册培训。

前端采用Vue.js框架，后端采用SpringCloud框架，使用waterdrop作为关系数据库，Neo4j作为非关系数据库，HDFS作为多源异构数据存储平台，Hive作为分析引擎。配合MyBatis半自动生成bean，使用Redis，RabbitMQ，Druid等组件来提升系统速度。



中医药疫病防治体系构建系统总经费20万，采用SpringBoot + Vue.js + MySQL + Neo4j框架，汇辑中国传统医学疫情防控史料数据，提供文献展示平台和文本标注平台，支持半自动化标注古籍数据。根据疫病数据构建疫病防治方药应用的知识图谱，以提供疫病趋势预测与疫病防控决策的方案。
项目使用Mybatis对MySqL中的数据自动生成各种bean导入到项目中去，以此来实现项目的增删改查功能。
本人主要负责使用SpringBoot和MyBatis框架进行任务标注功能的开发。利用HanLP工具包对文章进行自动标注，导出标注任务统计结果PDF报告。同时完成相关技术文档编写、向甲方演示汇报、与甲方进行沟通优化项目。
目前项目已完成数据库构建、软件开发、部署云服务器，处于迭代更新阶段。

前端采用Vue.js框架，后端采用SpringCloud框架，使用mysql作为关系数据库，Neo4j作为非关系数据库。配合MyBatis半自动生成bean，使用hanlp作为文本标注工具。

# 请介绍处理海量数据时候常用的解决思路，说明优势劣势及其适用场景。

海量数据的处理，大致有6种方法：

1.分而治之/Hash映射 + Hash_map统计 + 堆/快速/归并排序

先映射，而后统计，最后排序

分而治之/hash映射：针对数据太大，内存受限，只能是：把大文件化成(取模映射)小文件，即：大而化小，各个击破，缩小规模，逐个解决

hash_map统计：当大文件转化了小文件，那么我们便可以采用常规的hash_map(ip，value)来进行频率统计。

堆/快速排序：统计完了之后，便进行排序(**可采取堆排序**)，得到次数最多的IP。

例如，对于“海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10”的问题，可以选择遍历一遍所有数据，重新hash取模，如此使得同一个元素只出现在单独的一台电脑中。采用堆排序，在每台电脑上求出TOP10，可以采用包含10个元素的堆完成（TOP10小，用最大堆，TOP10大，用最小堆）。将这100台电脑上的TOP10组合起来，共1000个数据，再利用上面类似的方法求出TOP10。

2.多层划分

本质上还是分而治之的思想，重在“分”的技巧。适用于求解第k大，中位数，不重复或重复的数字。因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。

例如，在5亿个int找它们的中位数，将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。

3.Bloom filter/Bitmap,可以用来实现数据字典，进行数据的判重，或者集合求交集

将hash函数对应的值的位数组置1，查找时如果发现所有hash函数对应位都是1说明存在，很明显这个过程并不保证查找的结果是100%正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。

4.Trie树/数据库索引/倒排索引

Trie树，适用于数据量大，重复多的数据，但是数据种类小可以放入内存

例如，对于“寻找热门查询，300万个查询字符串中统计最热门的10个查询”的问题，查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。

数据库索引，适用于大数据量的增删改查，利用数据的设计实现方法，对海量数据的增删改查进行处理

倒排索引，适用于搜索引擎，关键字查询。存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。

5.外排序

适用于大数据的排序，去重，利用外排序的归并方法，置换选择败者树原理，最优归并树。

例如“有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16个字节，内存限制大小是1M。返回频数最高的100个词”，内存太小不够用来Hash，所以内存可以当作输入缓冲区使用，用来排序。

6.分布式处理之Mapreduce

适用于数据量大，但是数据种类小可以放入内存。

MapReduce是一种计算模型，将大批量的工作（数据）分解（MAP）执行，然后再将结果合并成最终结果（REDUCE）。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。本质上就是归并排序。



# 大数据生态痛点

面对大量、多样、高速、价值密度低的大数据，产生了多样的方法解决，Hadoop生态圈可以解决大量数据的存储与分析计算问题，HDFS让大量的数据能横跨成百上千台机器，MapReduce可以快速的并行处理，Yarn为运算程序提供服务器运算资源，Hive可以将SQL语言翻译成MapReduce程序，Spark/Flink弥补基于MapReduce处理数据速度上的缺点，把数据装载到内存中计算而不是去读硬盘。但是如此庞大的大数据生态圈依然有着很多痛点问题。

**数据孤岛问题**：组织内部的数据，零散分布在多个系统之中，共享性差，总部无法确认拥有多少数据资产。形成数据孤岛问题，通常是因为组织发展初期，没有做好数据管理规划。组织壮大后，老部门用旧系统，新部门用系统，系统属于不同厂商不同产品，导致数据孤岛问题严重。比如政务行业，医疗行业，银行业，大型的集团公司等，总部都很难准确掌握实时准确的数据，从而影响高层决策。

**数据质量差**：没有设定好的数据标准，导致数据的完整性，准确性，一致性等不符合规范；很多元数据的必要属性未被填充，比如注释，长度，精度等。比如用户信息管理系统中，没有设置好手机号，身份证的长度和精度，数据输入出现错误，残缺现场，导致系统内存在很多无效数据，降低数据质量。

**数据标准不一致**：各业务系统都存在自己的标准，且不统一，统一业务元素对应多种数据类型和长度。同一英文字段对应多个中文名，番茄也存在中文的一对多现象。还存在着表，字段命名不规范，命名随意性很强的情况。

**数据影响分析困难**：很多大组织的历史数据庞大繁杂，表之间的关系不清晰；某些元数据发生变更，它的影响范围无法评估；还存在着数据找不到接口人，针对其对应用会很困难。

**数据管理混乱**：企业没有相应的数据管理制度，数据出问题无法找到解决流程，解决方法。没有相关的数据管理组织，角色分工不清晰，没有建立追责机制；还有数据管理系统不完善，数据的添加，删除，变更，销毁，通知等操作，无法实现。

**数据安全无保障**：组织内部数据权限划分不清，没有设置访问人，审核人，管理人等；数据没有对信息的机密程度进行分层管理，导致机密信息泄露；账号与权限没有进行关联跟踪，不知道是谁何时何地访问，遇到问题，无法进行追责，非正常访问也无法捕捉。

在起步阶段，跨部门数据专业工作组需要具备以下最小职能：

1、建章立制：编制大数据汇通工作的规范流程和管理办法，建立企业级数据量化评估体系，确保各系统按要求开放数据资产、统一数据采集、保障数据质量。

2、汇通实施：将各部门盘点的数据资产统一采集汇聚到大数据平台，通过大数据技术将数据融合融通，并向全企业开放使用。

而各部门数据专员最小的职责包括：

1、数据资产盘点：及时盘点和维护部门内数据资产，协助工作组审核IT项目数据汇通合规性。

2、数据融合融通：收集部门内的数据融合融通需求并提交，协调部门内各领域专业知识分享。

3、数据质量保障：协助工作组督导部门内的大数据汇通对接保障，组织协调解决大数据汇通过程中的数据质量问题。

总之一句话，要彻底打破企业的数据部门墙，一方面依赖企业对于IT和数据的认知和重视程度，能够给予组织、机制和资源上的保障，另一方面则需要数据团队积极作为，给出合理的策略，否则就没什么希望了。

# 投递公司

| 序号 | 公司名称     | 城市 | 备注                                                         |
| ---- | ------------ | ---- | ------------------------------------------------------------ |
| 1    | 携程         | 上海 |                                                              |
| 2    | 腾讯         |      |                                                              |
| 3    | 美团         |      |                                                              |
| 4    | 阿里         |      |                                                              |
| 5    | 字节         |      |                                                              |
| 6    | 哔哩哔哩     | 上海 |                                                              |
| 7    | 华为         | 南京 |                                                              |
| 8    | 荣耀         |      |                                                              |
| 9    | 中兴         |      |                                                              |
| 10   | 京东         |      |                                                              |
| 11   | vivo         |      | 答题                                                         |
| 12   | oppo         |      |                                                              |
| 13   | 小红书       |      |                                                              |
| 14   | 网易         |      | 回答三个问题                                                 |
| 15   | 小米         |      |                                                              |
| 16   | 百度         |      | 后端                                                         |
| 17   | 米哈游       |      |                                                              |
| 18   | 中行         |      |                                                              |
| 19   | 招商银行     |      |                                                              |
| 20   | 交通银行     |      |                                                              |
| 21   | 宁波银行     |      |                                                              |
| 22   | 上海银行     | 未投 |                                                              |
| 23   | 江苏银行     |      |                                                              |
| 24   | 贝壳         |      |                                                              |
| 25   | 恒生         |      |                                                              |
| 26   | 拼多多       |      |                                                              |
| 27   | 爱奇艺       |      |                                                              |
| 28   | 美的美少年   |      |                                                              |
| 29   | 博西家电     |      | 博西家电：百色家电，工厂内部物流信息技术组对物流订单的优化，提供端到端可见性的系统。下周二之前有具体的安排，本月20号有建邺区的面试，上班在栖霞区，有班车，7月3日开始8周实习，每日220，一周五天，两月8800 |
| 30   | 蚂蚁         |      |                                                              |
| 31   | 网易雷火     |      |                                                              |
| 32   | 腾讯云智     |      |                                                              |
| 33   | 江苏银行     |      | 连云港分行 苏州分行                                          |
| 34   | 帆软         |      |                                                              |
| 35   | 天翼电信     |      | **12505**                                                    |
| 36   | ==趋势科技== |      |                                                              |

![image-20230516100231882](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230516100231882.png)

# 自我介绍

面试官您好，我是沙雪琪，南京理工大学计算机院学生。研究生期间，做了很多数据库构建、数据管理、数据规范的项目，积累了一些数据工程的经验，因此想从事数据开发方向。

我拥有丰富的前后端开发经验，参与研发了HS效能数据服务系统，负责设计武器弹药等八大数据库的数据规范作为本体标签树，负责图数据库的构建、管理和批量导入，支撑整个知识图谱部分的前后端开发。另一个项目是中医药疫病防治体系构建系统，聚焦疫病古籍数据，构建疫病防治和方药应用体系，提供疫情预测与防控方案。

竞赛方面，我参加了多次数学建模竞赛，获得南理工数学建模竞赛一等奖，亚太数据建模竞赛二等奖。

关于奖学金，研究生和本科期间，我获得了每一年度评比的奖学金，本科三次以及研究生两次的一等学业奖学金，另外，本科期间也获得了特等奖学金——三好学生标兵和三好学生。

我曾担任项目组小组长职务，具有较强的团队精神，对待工作非常认真负责，乐于学习新知识。专业知识的学习让我有了扎实的基础，项目的打磨让我有较强的实践能力、抗压能力、紧急情况处理能力。以上是我的自我介绍。



校赛：综合运用主成分分析、聚类分析、灰色关联度分析、距离判别分析模型等多种方法建立了数学模型，较好地解决了大学生消费水平的分类问题、消费特征描述问题与分类精度的确定问题。通过数据清洗、主成分分析、聚类分析等方法提取学生校园消费的特征，包括消费时间、三餐占比，对学生的消费水平进行分类，对校园需要帮助的同学进行精准识别，为高校温情关怀提供有效的数据依据。对食堂窗口进行分类，分为高消费窗口、经济型窗口和低消费窗口。

APMCM：研究熔融过程中模具通量的颜色和面积变化。使用OCR、检测框校正和文本识别算法提取图像信息，综合运用灰度转换、图像增强、图像去噪、轮廓提取、颜色聚类和颜色识别等方法分析图像的周长、面积、颜色比例、颜色HSV值等特征。结合熔融结晶动力学模型对导线温度与时间的关系进行分阶段建模。

列表元组

# 研究所

14所

55所

724

8511
