# Redis

## Redis介绍

key value类型，基于C语言的内存数据库，支持多种数据类型，支持事务、持久化、Lua脚本。没有外部依赖，一般使用linux部署。

Redis速度快的原因：
基于内存，内存的访问速度是磁盘的上千倍；
基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是**单线程事件循环和 IO 多路复用**；
Redis 内置了多种优化过后的数据结构实现，性能非常高。

分布式缓存常见的技术：Redis和Memcached

|                  | Redis                                      | Memcached          |
| ---------------- | ------------------------------------------ | ------------------ |
| 支持的数据类型   | 更丰富， k/v ，list，set，zset，hash       | 仅 k/v             |
| 数据持久化       | 支持，将数据保持在磁盘，重启时再次加载使用 | 全存在内存         |
| 灾难恢复机制     | 有，磁盘                                   | 没有               |
| 网络模型         | 单线程多路复用                             | 多线程非阻塞IO复用 |
| 过期数据删除策略 | 惰性删除+定期删除                          | 惰性删除           |
|                  | 支持订阅模型、**事务、Lua脚本**            | 均不支持           |
|                  | 支持更多编程语言                           |                    |

Redis使用缓存：
高性能：缓存读取数据非常快，基于空间局部性原理。
高并发：Mysql的QPS一般1w，使用缓存可达到30w。直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的

## 缓存读写策略

|        | 旁路缓存模式(常见)                                           | 读写穿透(少见)                                               | 异步缓存写入(少见，写性能高)                                 |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 英文   | Cache Aside Pattern                                          | read write through                                           | Write Behind Pattern                                         |
| 描述   | 最常见                                                       | 服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。 cache 服务来负责 cache 和 db 的读写。<br />cache和db同时写入 | 也是cache负责cache和db的读写<br />只更新缓存，不直接更新 db，而是改为**异步批量**的方式来更新 db |
| 写过程 | **先更新db，再删除cache**（一般不会出现数据不一致，因为cache速度快） | 先查cache，如果存在更新cache，让cache自己去更新db；如果不存在，直接更新db。 |                                                              |
| 读过程 | 先检查cache，有的话直接返回；没有的话取db中读取，然后放入cache。 | 先查cache，有的话直接返回；没有的话，cache自己去找db读取，放入cache返回给用户（这个过程由cache完成，而在旁路缓存中由用户完成） |                                                              |
| 优点   | 适合多读场景                                                 |                                                              | 写性能高，消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。 |
| 缺点   | 首次读取一定不命中：**热点数据预加载**；<br/>写操作频繁cache命中率低（老是删除cache数据）：同步更新db和cache，不过我们需要加一个锁/分布式锁来保证更新 cache 的时候不存在**线程安全**问题。 | 分布式缓存 Redis 没有提供 cache 将数据写入 db 的功能。       | **数据一致性**问题：比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。 |

## redis应用

| 应用         | 描述                                                         |
| ------------ | ------------------------------------------------------------ |
| 分布式锁     | 分布式锁可以用redis或者zookeeper实现                         |
| 限流         | 限流是保证**系统高可用**，radis+Lua                          |
| 消息队列     | Redis 自带的 list 数据结构可以作为一个简单的队列使用         |
| 复杂业务场景 | Redis 以及 Redis 扩展（比如 Redisson）提供的数据结构，实现复杂场景： bitmap **统计活跃用户**、通过 sorted set 维护排行榜 |

### redis实现分布式锁

一个JVM控制资源共享（本地锁）： `ReetrantLock` 类、`synchronized` 关键字
多个JVM共享同一资源（分布式情况）：分布式锁

一个最基本的分布式锁需要满足：
**互斥** ：任意一个时刻，锁只能被一个线程持有；
**高可用** ：锁服务是高可用的。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。
**可重入**：一个节点获取了锁之后，还可以再次获取锁。

分布式锁的核心就是互斥，**SETNX**命令

### 限流

| 限流方案   | 描述                                                       |
| ---------- | ---------------------------------------------------------- |
| 计数器     | 原子类计数器`AtomicInteger`、`Semaphore`信号量             |
| 漏桶算法   | 漏桶是“系统处理能力极限”，流出速率小于流入速率时，拒绝流入 |
| 令牌桶算法 | 通过控制桶的容量、发放令牌的速率，来达到对请求的限制。     |
| Redis+Lua  | Lua脚本类似mysql存储过程，一段原子执行的逻辑代码块         |

## redis数据结构

**5 种基础数据结构** ：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。
**3 种特殊数据结构** ：HyperLogLogs（基数统计）、Bitmap （位存储）、Geospatial (地理位置)。

| 基础数据结构     | 描述                                                         | 应用场景                                                     |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| String           | 二进制安全，存储任何类型，（字符串、整数、浮点数、图片、序列化对象）<br /> **简单动态字符串**（Simple Dynamic String，**SDS**），保存文本和二进制数据，不会缓冲区溢出 | 存储常规数据：缓存 **session、token**、图片地址、序列化对象（get set命令）<br />计数场景：用户单位时间的请求数（简单限流）、页面单位时间的访问数 |
| List             | 链表，C没有内置链表，这个基于linkedList                      | 信息流展示：最新文章、最新动态（lpush lrange）<br />消息队列：不建议 |
| Hash             | String 类型的 field-value（键值对） 的映射表                 | 对象数据存储场景：修改对象某些字段的值（hset）               |
| Set              | 类hashset，无序集合<br />交集、并集、差集                    | 数据不能重复的场景<br />多个数据源交集、并集和差集的场景（共同好友） |
| Sorted Set       | 有序集合，增加了一个权重参数 score，按 score 进行有序排列    | 排行榜场景                                                   |
|                  |                                                              |                                                              |
| **特殊数据结构** |                                                              |                                                              |
| bitmap           | 连续的二进制数字（0 和 1），一个比特位表示元素值（boolean都是8byte1字节），极大的节省储存空间 | 用户签到情况、活跃用户情况（setbit getbit）                  |
| hyperloglog      | 基数计数概率算法，只需要 12k 的空间就能存储接近`2^64`个不同元素（数学的魅力），稀疏矩阵，稠密矩阵 | 数量量巨大的**计数**场景：热门帖子统计                       |
| GEO              | 地理空间索引                                                 |                                                              |



## 持久化机制

| 持久化方案 | RDB持久化（快照）                                            | append-only file, AOF只追加文件                              | RDB 和 AOF 的混合持久化     |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------------- |
| 描述       | 通过创建快照来获得 **某个时间点** 的内存数据副本<br />可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能） | 1.命令追加append：所有命令写入到AOF缓冲区<br />2.文件写入write：AOF缓冲区数据通过**系统调用**，写入到内核缓存的AOF文件中（未落盘）<br />3.文件同步fsync：根据fsync持久化策略决定如何落盘（落盘）<br />4.文件重写rewrite ：定期对 AOF 文件进行重写，防止过大，压缩数据（新的AOF与旧的状态一致）。<br />5.重启加载load ： Redis 重启时加载aof文件进行数据恢复。 | RDB 的内容写到 AOF 文件开头 |
| 实现       | `save` : 同步保存操作，会阻塞 Redis 主线程；<br /> `bgsave` : fork 出一个子进程，子进程执行，不会阻塞 Redis 主线程，默认选项。 |                                                              |                             |
| 优缺点     | **默认**的持久化方式，通过快照落盘<br />压缩的二进制数据，文件小，适合数据备份灾难恢复。<br />**无法实时**持久化数据（生成过程繁琐），数据丢失的多 | 实时性更好，追加操作轻量级，最多丢失1s的<br />类似mysql的binlog日志，大很多 |                             |
| 其他       | Redis 保存的数据丢失一些也没什么影响的话，可以选择使用 RDB。<br />不建议单独使用 AOF，重写太占内存<br />如果保存的数据要求安全性比较高的话，建议同时开启 RDB 和 AOF 持久化或者开启 RDB 和 AOF 混合持久化。 | 先执行命令写内存，再记录日志写磁盘（先操作数据，再记账）：  <br />避免额外的检查开销； 不会阻塞当前的命令执行。 | 4.0的优化                   |

![AOF 工作基本流程](https://oss.javaguide.cn/github/javaguide/database/redis/aof-work-process.png)

fsync策略（AOF持久化方式）：

| fsync方案            | 描述                                                         | 区别                                                         |
| -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| appendfsync always   | 主线程调用 `write` 执行写操作后，后台线程立刻同步AOF文件（刷盘） | 调用fysnc函数进行同步刷盘的时机。<br />always严重降低redis性能；everysec兼具了数据和写入性能。 |
| appendfsync everysec | 每秒钟调用 `fsync` 函数进行一次刷盘                          |                                                              |
| appendfsync no       | OS决定何时刷盘（linux默认30s一次）                           |                                                              |

## 线程模型

Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型 ，虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，保证了高效性和简单性。

![imgTypora/image-20230503204340257.png  0 → 100644](https://gitee.com/ziye1005/test-typora/raw/6cd39a792a4dda4b24e4f8292c1c7b5d5a8c5125/imgTypora/image-20230503204340257.png)

为何不使用多线程：（6.0之后引入多线程）

单线程编程容易并且更容易维护；
Redis 的性能瓶颈不在 CPU ，主要在内存和网络；
多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

## 内存管理

给缓存数据设置过期时间：如果不设置，内存分分钟OOM；用户登录的 token 可能只在 1 天内有效，如果数据库来判断会很慢。
除了字符串类型有自己独有设置过期时间的命令 **setex** 外，其他方法都需要依靠 **expire** 命令来设置过期时间 。另外， **persist** 命令可以移除一个键的过期时间。

**过期字典**判断数据是否过期

过期数据删除：**惰性**删除（取出 key 的时候才对数据进行过期检查，CPU友好，但可能大量应删除的key未删除）
**定期**删除（定时删除过期key，内存友好）

## redis事务

满足ACID，没有事务回滚（回滚指的是原子性问题：如果事务执行一半宕机了，会回到执行之前的状态，一个事务要么全部执行，要么全部不执行）。

## redis优化

1.使用**批量操作**减少网络传输：
原生批量操作（mget获取多个key）；
对于不支持批量操作的命令，利用**pipeline（流水线)** 将一批 Redis 命令封装成一组，**不是原子操作**
Lua脚本：原子操作，依然不支持回滚

2.大量 key 集中过期问题：
给 key 设置**随机过期时间**（多用）。
开启 lazy-free（惰性删除/延迟释放） 。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。

3.bigkey
key对应的value很大（> 10KB） :
使用--bigkeys分析出bigkey；
分析RDB文件

4.内存碎片：
redis申请的数据空间往往>所需空间（zmalloc）,频繁修改 Redis 中的数据也会产生内存碎片。
清理： 自带的**内存清理**，config set 命令，避免内存碎片率过大的问题。

## 生产问题

1.缓存穿透：
大量请求的 key 是不合理的，不存在于缓存中 && 不存在于数据库中，缓存无用了。
解决方法：参数校验；缓存无效 key（把查不到的key页缓存在内存中，但恶意攻击更换无效key时无法预防的）；
**布隆过滤器**（ 说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在）

2.缓存击穿：
key对应的热点数据，不存在于缓存中 && 存在于数据库中，缓存的**热点数据过期**了。
解决：设置热点数据永不过期或者过期时间比较长。

3.缓存雪崩：
缓存中的大量或者所有数据失效，导致大量的请求都直接落到了数据库上。可能时redis服务不可用，或者热点缓存失效。

4.redis阻塞：
O(n)全表扫描：例如`keys *` `lrange`命令。
save指令创建RDB快照：阻塞创建。
AOF日志记录阻塞，刷盘阻塞，重写阻塞

## 使用规范

1. 使用连接池：避免频繁创建关闭客户端连接。

2. 尽量不使用 O(n)指令，使用 O(N)命令时要关注 N 的数量。有遍历的需求可以使用 `hscan`、`sscan`、`zscan` 代替。

3. 使用批量操作减少网络传输 ：原生批量操作命令（比如 `mget`、`mset`等等）、pipeline、Lua 脚本。

4. 尽量不使用 Redis 事务：Redis 事务实现的功能比较鸡肋，可以使用 Lua 脚本代替。

5. 控制 key 的生命周期：避免 Redis 中存放了太多不经常被访问的数据。

   

## 主从复制-读写分离-数据一致性

因为缓存中读的并发量要远远大于写的并发量，**基于RDB的主从复制读写分离架构**：master读写，slave只能读。

slave初始化：ping master节点，如果ping通，salve就会把master上的rdb文件复制到slave节点，加载到内存中；如果master发生写，会通知slave进行rdb的更新。

当master和slave链接良好时，master向slave**发送命令流**来完成salve更新；
当master和salve链接中断时，salve将尝试**重新连接**并尝试进行**部分重新同步**。当无法进行部分重新同步时，salve将进行**全部重新同步**，需要master创建所有的快照并发给salve。

2.8之前**全量同步**：master会将内存数据通过bgsave落地rdb文件；将接收到的客户端**写指令存放到复制缓冲区**中。当rdb快照构建完毕之后，master会将rdb和写指令全部发送给slave，全量同步对系统的性能和资源访问造成影响。
2.8之后增量复制：引入PSYNC，增加了一个复制积压缓冲，slave会通过PSYNC命令发送自己的Replication ID和Offset。这样主机只需要向副本发送增量部分。

redis在master和slave端异步复制（同步数据时，依然可以进行数据查询）。但slave初始化时，需要删除本身的旧数据集加载新数据集，这短暂的期间是不能被客户端连接的。
一个master可以连接多个副本，一个副本也可以连接多个副本，类似于级联结构。

数据一致性：先更新db，再删除cache

# 数据仓库DW

## 基本概念

问题：多源异构、脏乱差的数据现象。

目的：具备数据的**管理、存储、分析计算功能**，为企业制定决策提供**数据支持**

### 分层

![image-20230505142433452](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230505142433452.png)

分层不是统一的标准，基于该分层会有些微变动。数仓分为离线数仓和实时数仓，但是都分为以下5层。由底向上数据量越来越少，上层依赖下一层。

原始数据层ODS(Operational Data Store)：存放未经处理的原始增量数据，结构必须与源系统保持一致。离线或准实时数据接入，数据**暂存备份**
公共维度层DIM：构建维度模型中的**维度表**，数据来自ODS层
数据明细层DWD (data warehouse detail)：存放事实表，数据来自ODS层，做数据清洗、脱敏、主题汇总
数据汇总层DWS(data warehouse summary)：对明细数据预聚合，保存中间表，减少重复计算
数据应用层ADS(application data service)：做数据统计分析

### 数据组成

![image-20230505090839205](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230505090839205.png)

### 数仓过程

![image-20230505092059237](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230505092059237.png)

### 技术选型

| 技术                 | 离线数仓          | 实时数仓          |
| -------------------- | ----------------- | ----------------- |
| 数据采集传输         | Flume kafka DataX | Flume kafka       |
| 数据存储             | mysql HDFS        | mysql Hbase redis |
| 数据计算             | hive spark        | flink             |
| 数据查询，响应速度快 | presto druid      | clickHouse        |
| 数据可视化           | superset          | sugar             |
| 任务调度             | dolphinScheduler  |                   |
| 集群监控             | zabbix            | prometheus        |

### 系统数据流程

<img src="https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230505094459892.png" alt="image-20230505094459892" style="zoom: 150%;" />

业务数据通过业务服务器放到mysql，用户行为数据通过日志服务器放到日志服务器本地文件中，两者都需要nginx做负载均衡和请求转发，防止数据倾斜。

发送到离线数仓HDFS用spark和hive计算：业务数据:arrow_right:离线数仓HDFS：全量同步通过DataX发送给HDFS，增量同步走kafka
日志数据:arrow_right:离线数仓：使用flume，发送到kafka消峰（为了防止数据激增），再通过flume取到HDFS

hadoop集群离线数仓建模：五层，**最终指标存储在ADS层**，再通过可视化方式展示。将每日增量数据通过dataX每日同步到mysql表中（为了查询速度），superSet从mysql中查询数据。

发送到实时数仓flink计算：业务数据和用户行为数据从kafka中查询（kafka解耦）

flink实时数仓建模：ods层就是kafka的copy，dwd时kafka的另一个copy，dim层用hbase存储，用redis旁路缓存加速，dws层存储在clickhouse，通过springboot jdbc工具聚合，用sugar实时可视化。

## 数仓模型

![image-20230505103536124](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230505103536124.png)

将数据有序的组织和存储在关系型数据库中，有两种：

|          | ER模型                                                       | 维度模型                                                     |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 使用场景 | 业务系统关系型数据库                                         | 数仓                                                         |
| 出发点   | 整合数据                                                     | 数据分析                                                     |
| 描述业务 | 实体和关系                                                   | **事实**（业务过程下单支付等，用户行为数据的**行为**信息）<br />**维度**（业务过程的环境，用户行为数据的**环境**信息） |
|          | 用**ER模型**来描述企业业务，并用**规范化**的方式表示出来，在范式理论上符合**3NF**（去冗余）。<br />关系：一对一、一对多、多对多、多对一 | 更加简洁，让用户如何更快的完成需求分析以及大规模复杂查询的响应性能。<br />**进行数据分析时，先找到事实表，找到所需要的维度表，对维度字段进行过滤和分组，不需要层层join去找**，简洁很多 |
| 包括     | 1NF 2NF 3NF                                                  | 雪花、星型、星座                                             |

## 事实表（数仓维度建模的核心）

事实表包含维度引用（**维度表外键**），该业务过程的**度量值**（通常是可累加的数字类型字段，次数、个数、件数、金额）。
事实表通常比较“细长”，即列较少，但行较多，且**行的增速快**。
分类：事务事实表、周期快照事实表、累积快照事实表。这几种表不冲突，是互补的，可以同时存在

### 事务事实表（最重要）:star:

记录各业务过程，它保存的是各业务过程的**原子操作事件**(每行数据是一次下单记录)，即**最细粒度**的操作事件（order_detail比order_info细粒度，因此下单事务事实表需要和order_detail一样）

设计流程：
选择业务过程（下单，取消订单，付款，退单），通常一个业务过程对应一张事务事实表
声明粒度：为每个业务声明粒度，选择最细粒度，以满足各种细节程度的需求。
确定维度：确定与每张事务型事实表相关的维度，决定了分析出的指标的丰富程度
确定事实：每个业务过程的度量值

优缺点：
理论上可以支撑所有统计分析需求；
但有时候会逻辑复杂效率低下。

例如：
1.存量型指标（商品库存，账户余额）：获取京豆和使用京豆各维护一张事务事实表，求剩余京豆，需要两个表分组聚合后join取出该用户的余额京豆。
2.多事务关联统计（大表join大表，下单到支付的**时间间隔**的平均值）

### 周期快照事实表——存量型指标

周期地给mysql的事实表打快照。
对存量型指标：计算并保存最新结果，定期==全量更新==到数仓（**所有**数据复制到目标表）
对状态型指标（空气温度，行驶速度）：无法捕获到原子事务操作，无法用事务事实表记录，只能每隔30s打一次数据快照。

设计流程：
确定粒度：由采样周期和维度决定（统计每个仓库每种商品的库存，粒度：每日-仓库-商品）。
确定事实：事实由统计指标确定，商品库存。

事实（度量值）类型：
可加事实：可以按照与事实表相关的**所有维度**进行累加，都是有意义的，例如**所有的事务型事实表**
半可加事实：只能按照与事实表相关的**一部分维度**进行累加，才是有意义的，例如**所有的周期快照事实表按照时间累加都无意义**。（商品库存按照时间累加毫无意义，按照仓库和商品累加还可以）
不可加事实：完全不具备可加性，例如比率型事实（退货率）。应该尽量避免

### 累计快照事实表——多事务关联统计

多个关键业务过程联合处理而构建的事实表，维度外键是多个事务表的外键，度量值是多个事务表的度量值。**通常具有多个日期字段**，求**时间间隔的指标**。==增量同步==，一条数据不是一次写入完整的。

设计流程：
选择业务过程：多个业务过程对应一张累积性快照表
声明粒度：尽量选择最细粒度，不强制。
确定维度：每个业务过程都要有一个日期维度。
确定事实：多个业务过程的度量值

## 维度表（数仓的基础灵魂）:star:

全量同步 vs 增量同步：<font color='red'>一般情况下：维度表、周期快照、每日全量快照表采用全量；事务事实表、累计快照、拉链法采用增量。</font>

### 设计步骤

确定维度：理论上每个相关维度均需对应一张维度表。如果多个事实表与同一维度相关，只创建一张维度表；如果维度表属性很少（支付方式），**维度退化**到事实表的属性。

确定主维表和相关维表：均指业务系统中与某维度相关的表，粒度最细的为主维表，其余为相关维表。**维度表粒度与主维表相同**。

确定维度表字段：可以从主维表/相关维表中选择，或者从主维表/相关维表中加工。

### 维度表设计要点

1. 规范化与反规范化

规范化（雪花模型）：使用范式设计数据库，减少数据冗余。
**反规范化**（**星型模型**）：多张表join到一张表，减少join操作，提高查询效能。
星座模型：多个星型/雪花模型通过**共用的维度表**连在一起，组成星座。

雪花模型和星型模型的区别在于是否靠近3NF，**一般要星型模型。维度表一般是很不规范化的**。

![image-20230505120740862](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230505120740862.png)

2. 维度变化（每日全量快照，拉链）

维度属性通常会变化（手机号码），数仓需要反映历史的变化，需要保存维度的历史状态。分别是全量快照表和拉链表。

每日全量快照表：每天保存一份**全量**数据，不管变不变。用起来不高效，而且占空间。

**拉链表**：只记录变化，记录每条信息的生命周期，一行表示一个状态，一旦一条记录的生命周期结束，就重新开始一条新的纪录。只做**增量**。适合数据会变化但不会频繁变化的情况。
通过生效开始日期<=某个日期<= 生效结束日期来做全量切片

![image-20230505121806535](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230505121806535.png)

3. 多值维度

事实表中一条记录在某个维度表中有多条记录与之对应（下单事实表中的一条记录为一个订单，一个订单可能包含多个商品，商品维度表中就可能有多条数据）。
解决方法：**将事实表粒度细化**（order_info细粒度到order_detail）

4. 多值属性

某个属性同时有多个值
解决方法：将多值属性放到一个字段，该字段内容为key1:value1，key2:value2

## 数仓构建流程

![image-20230505144301895](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230505144301895.png)

### 明确数据域

根据业务过程或者部门划分数据域，一个业务过程只能属于一个数据域。（交易域、流量域、用户域、互动域）

### 构建业务总线矩阵

包含维度模型所需的所有事实和维度，以及各业务过程与各维度的关系。矩阵的行是一个个业务过程事实表，矩阵的列是一个个的维度表，行列的交点表示事实与维度的关系。

一个业务过程对应维度模型中一张事务型事实表，一个维度则对应维度模型中的一张维度表。所以构建业务总线矩阵的过程就是设计维度模型的过程。

总线矩阵中通常只包含事务型事实表，另外两种类型的事实表需**单独设计**。

后续的DWD层以及DIM层的搭建需参考业务总线矩阵。

![image-20230505145216796](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230505145216796.png)

### 明确统计指标

指标定义标准化

| 指标分类 | 定义                                                         |
| -------- | ------------------------------------------------------------ |
| 原子指标 | 代表某一业务过程的度量值的聚合逻辑（订单总额），不够明确，辅助定义完整指标 |
| 派生指标 | 基于原子指标，=原子指标+统计周期+业务限定+统计粒度（最近一天各省份手机品类的订单总额），可以通过一张事实表聚合分组得到 |
| 衍生指标 | 基于派生指标复合而成。（最近30天各品牌退货率）               |

### 汇总模型设计

明确指标类型，如果是衍生指标，找派生指标，找派生指标的原子指标。DWS表相当灵活，每个人设计出来的解题逻辑可能不一样。

## 数仓 vs 数据湖 vs 数据中台

数据湖是一个企业的**原始数据保存区**，可以实现数据的集中式管理，可以存储所有类型的数据：结构化、半结构化、非结构化；作为数仓的数据来源。
数仓只能处理结构化的数据，并且必须与源系统的模型相吻合，才能进入数仓。数仓可以存储维护长期数据，数据可以按需访问，可以转化为可视化的报表。“
数据中台：对海量数据进行采集、计算、存储、加工，统一标准和口径

![img](https://pic4.zhimg.com/80/v2-8ac4a200c583b1b1845c2fccc28e1d4f_720w.webp)

## CSDN整理

### 概念模型 逻辑模型 物理模型

是数据库建模数仓建模的主要步骤

|      | 概念模型CDM                                      | 逻辑模型LDM                                                  | 物理模型PDM                                                  |
| ---- | ------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 描述 | 用户需求的概念，用ER图表示<br />不定义属性和主键 | 对概念模型进行分解细化，转化为具体的数据模型，确定属性、主键、外键、范式处理<br />不考虑物理上的实现 | 在逻辑模型的基础上，考虑技术实现因素，进行数据体系结构设计。<br />确定所有的表和列，定义外键，基于用户的需求可能要进行反范式化 |

### SCD处理方式

slowly changing dimensions 缓慢变化维度

1）直接覆盖：**不记录历史数据**，薪数据覆盖旧数据

2）新加一行数据（纵向扩展）：使用代理主键+生效失效时间或者是代理主键+生效失效标识（**保存多条记录**，直接新添一条记录，同时保留原有记录，并用单独的专用字段保存）

3）新加两个字段（横向扩展）：一个是previous，一个是current，每次更新只更新这两个值，但是这样职能**保留最近两次的变化**（添加历史列，用不同的字段保存变化痕迹，因为只保存两次变化记录，使用与变化不超过两次的维度）

### 缺失维度数据和重复数据

缺失维度：默认值填充 删除数据 外部关联补全
重复数据：去重 合并数据 保留最新

### 数仓性能优化

确定合适的数据模型（采用星型、雪花型等减少join）

合理的索引设计（适当索引）。

优化查询语句：避免使用子查询、过多的连接操作和复杂的函数计算等。

分析查询热点：通过监控查询日志等手段，了解用户最常用的查询语句和表，对热点查询进行优化。

数据分区：将数据划分为不同的分区，可以减小查询范围，提高查询效率。

### 增量更新策略

考虑数据的唯一性、比较时间戳等因素，以确保数据不会出现重复。
标识数据记录：给一个唯一标识符，防止相同数据被多次插入。
使用时间戳：增量更新时，只处理时间戳比当前时间更晚的数据记录。
逐条比较，更新或者插入。
批量更新

# SpringCloud / springboot

## spring基础

spring支持==IOC和AOP==（Aspect-Oriented programming面向切片编程），方便访问数据库，集成第三方组件。

主要组件：

| 主要模块                | 组成                                                         | 功能描述                    |
| ----------------------- | ------------------------------------------------------------ | --------------------------- |
| Core container          | spring-core （核心工具类）<br />spring-beans ：对 bean 的创建、配置和管理<br />spring-expression ：支持表达式语言 | 基础模块，提供 IoC 依赖注入 |
| AOP                     | spring-aop ：提供了面向切面的编程实现<br />spring-instrument ：为 JVM 添加代理 |                             |
| Data Access/Integration | spring-jdbc ：对数据库访问的抽象 JDBC<br />spring-tx ：事务支持<br />spring-orm ：对 Hibernate、JPA 、iBatis 等 ORM 框架支持 |                             |
| Spring Web              | spring-web ：Web 基础支持<br />spring-webmvc ： Spring MVC 实现<br />spring-websocket ： 对 WebSocket 的支持 |                             |
| Messaging               | 为 Spring 框架集成一些基础的报文传送                         |                             |

Spring VS springMVC VS springboot VS springCloud

| 框架        | 描述                                                         |
| ----------- | ------------------------------------------------------------ |
| Spring      | 轻量级的控制反转(IoC)和面向切面(AOP)的容器框架，但某些配置繁琐，需要xml或java显式配置。 |
| springMVC   | Spring MVC是Spring的一个模块，一个web框架                    |
| springboot  | Spring boot，约定优于配置，简化了spring的配置流程            |
| springCloud | 构建于Spring Boot之上，是一个关注**全局的服务治理框架**      |

## SpringIOC

控制反转思想，将设计好的对象的控制权交给spring框架来管理，由IOC容器使用**注解完成对象的注入**，而不是new对象。控制（对象创建实例化管理的权力）反转（控制权交给外部环境，spring IOC容器）。

类似对象工厂，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的，不用考虑service底层的构造函数，只要配置好然后引用即可。

springBean：Bean指的是被IOC管理的对象。可通过xml或者注解配置。
bean对象：类的代理或代言人（实际上确实是通过反射、代理来实现的），这样它就能代表类拥有该拥有的东西了

1.bean的作用域：
singleton : IoC 容器中只有唯一的 bean 实例。bean 默认单例。
session（仅web可用）：bean只在当前session有效
prototype : 每次获取都会创建一个新的 bean 实例。连续 `getBean()` 两次，得到的是不同的 Bean 实例

2.bean线程安全
在类中定义一个 ThreadLocal 成员变量，将需要的可变成员变量保存在 ThreadLocal 中。
大部分bean都是没有实例对象的，所以一定是线程安全的。

## 注释与注解

注释：单行注释（//）多行注释（/*  */）文档注释（/ * * */）

注解：@注释名的形式，对程序做出解释， 可以被其他程序(比如:编译器等)读取，是有注解信息的处理流程的。本质是一个继承了Annotation 的特殊**接口**，注解不支持继承。

### 四类元注解

```java
1.@Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE})
2.@Retention(RetentionPolicy.SOURCE)
每个注解都需要有@Target（约束注解可以应用的地方，如方法method、类接口type、参数parameter、包package、构造函数constructor） @Retention（约束注解的生命周期，源码级别source、类文件级别class、运行时级别runtime），默认是class
SOURCE：注解在编译的时候消失（该类型的注解信息只会保留在源码里，源码经过编译后，注解信息会被丢弃，不会保留在编译好的class文件里）
CLASS（默认）：注解在解释的时候消失（该类型的注解信息会保留在源码里和class文件里，在执行的时候，不会加载到虚拟机中），如Java内置注解，@Override、@Deprecated、@SuppressWarnning等
RUNTIME：在JVM中也保留，因此可以通过反射机制读取注解的信息，如SpringMvc中的@Controller、@Autowired、@RequestMapping等。
    
3.@Inherited可以让注解被继承，但不是真正继承，被修饰的类的子类可以通过对象.getClass().getAnnotations获取该注解。
4.@Documented：描述注解是否被抽取到api文档中，会被直接生成到javadoc中
public @interface SuppressWarnings {
    String[] value();
}

@Inherited
@Documented
@Target({ElementType.FIELD,ElementType.TYPE,ElementType.METHOD})
@Retention(RetentionPolicy.RUNTIME)
@interface DocumentA {} // 这个注解是有Inherited的

@Documented
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@interface DocumentB{} // 这个注解没有Inherited

@DocumentA class A {}
@DocumentB class B {}

class AClass extends A {} // 继承有继承注解的A
class BClass extends B {} // 继承没有继承注解的B
public class DocumentDemo {
    public static void main(String[] args) {
        A instanceA = new A();
        AClass aClass = new AClass();
        System.out.println("@DocumentA class A：" + Arrays.toString(instanceA.getClass().getAnnotations()));
        System.out.println("A的子类：" + Arrays.toString(aClass.getClass().getAnnotations()));
        B instanceB = new B();
        BClass bClass = new BClass();
        System.out.println("@DocumentB class B:"+Arrays.toString(instanceB.getClass().getAnnotations()));
        System.out.println("B的子类：" + Arrays.toString(bClass.getClass().getAnnotations()));
    }
}
/**
@DocumentA class A：[@base.override.DocumentA()]
A的子类：[@base.override.DocumentA()]
@DocumentB class B:[@base.override.DocumentB()]
B的子类：[]
*/
```



@Test：起标记作用，告诉测试框架该方法为测试方法。
@Override：覆盖方法，重写父类方法
@Deprecated：已过时的方法
@SuppressWarnnings("unchecked")：有选择的关闭警告，传递一个string，包括path（路径不存在警告）、finally（子句不完成警告）、unchecked（未检查的转换警告）、all（以上全部警告）

### SpringMVC注解

1.*注册bean的注解*（将对象转化为bean对象，交给IOC容器）：

@Mapper：数据层 (Mapper)
@Service ：业务层 (Service)
@Repository ：**持久层 / 数据访问层组件(Dao)**
@Component ：描述各种组件(当组件不好归类时)
@RestController：控制层(Controller)并返回**JSON数据类型**，但不会再执行配置的视图解析器，也不会返回给jsp（java servlet pages）java服务器页面，返回值就是return里的内容。
该注解等同于：@Controller + @ResponseBody
@Controller：控制层 接收用户请求 执行 视图解析器 。
返回一个ModelAndView对象，传给指定的jsp（将传过来的ModelAndView对象解析后展示在页面上），封装后，最后返回给客户端一个Html页面。
@ResponseBody 将Java对象转为JSON。如果用ajax接收请求，必须使用该注解。如果没有加此注解，返回的是一个页面，return里面的内容会被认做是需要跳转页面的地址。
`@PathVariable`用于获取路径参数，`@RequestParam`用于获取查询参数

@Component VS @Bean：
@Component 注解作用于类，而@Bean注解作用于方法，是一个类的实例。

@Mapper VS @Repository：
mapper和dao都是数据层进行crud的实现方式，dao还可以是持久层，web开发

### IOC容器注解

IOC（Inversion of Conctrol）：依赖注入（DI），将设计好的对象的控制权交给spring框架来管理，使用注解获取而不是new对象。控制（对象创建实例化管理的权力）反转（控制权交给外部环境，spring IOC容器）。
需要的时候通过注解来注入(获取)，而不是传统的在你的对象内部直接控制(new 对象)。从而降低了程序的耦合性。

2.*使用Bean的注解*（已经配置好的bean从IOC中拿出来用，完成属性、方法的组装）：
@Autowired 按byType自动注入，获取对应的bean对象。如果注入的类型有多个实现类，则需要注入具体实现类的名称。
@Resource 按byName自动注入，获取对应的bean对象。（在声明一个Dao或者Service的对象之前）
当一个接口存在多个实现类的情况下，`@Autowired` 和`@Resource`都需要通过名称才能正确匹配到对应的 Bean。`Autowired` 可以通过 `@Qualifier` 注解来显式指定名称，`@Resource`可以通过 `name` 属性来显式指定名称

@Value 注入普通类型属性。（获取application.yml里面的常量时）

### RequestMapping注解

指定控制器可以处理哪些URL请求。
@GetMapping 查询方法
@PostMapping增添保存方法
@DeleteMapping删除方法
@PutMapping更新方法
@PatchMapping更新局部方法

### 其他注解

@author @param @return @exception @link @version // javadoc注解

@Select @Update @Insert @Delete // 数据库操作注解

## Spring AOP 统一异常处理

利用一种称为“横切”的技术，剖开封装的对象内部，**将分散的类对象的公共行为**（事务、日志、权限）**封装到一个可重用模块**——“Aspect”，提高重用性，降低耦合度。

基于动态代理，利用截取消息的方式，对该消息进行装饰，以取代原有对象行为的执行。用`@Order` 注解控制多个切面的执行顺序。

Spring AOP VS AspectJ AOP ：SpringAOP属于运行时增强，基于动态代理，更简单；AspectJ AOP是编译时增强，基于字节码操作，更迅速。

统一异常处理： `@ControllerAdvice` + `@ExceptionHandler` ，给所有或者指定的 `Controller` 织入异常处理的逻辑（AOP），当 `Controller` 中的方法抛出异常的时候，由被`@ExceptionHandler` 注解修饰的方法进行处理。

## SpringMVC

Model：dao和bean数据层；Controller：用户请求；View：视图渲染

1.核心组件：
`DispatcherServlet` ：**核心的中央处理器**，负责接收请求、分发，并给予客户端响应。
`HandlerMapping` ：**处理器映射器**，根据 uri 去匹配查找能处理的 `Handler` ，并会将请求涉及到的拦截器和 `Handler` 一起封装。
`HandlerAdapter` ：**处理器适配器**，根据 `HandlerMapping` 找到的 `Handler` ，适配执行对应的 `Handler`；
`Handler` ：**请求处理器**，处理实际请求的处理器。
`ViewResolver` ：**视图解析器**，根据 `Handler` 返回的逻辑视图 / 视图ModelAndView，解析并渲染真正的视图，并传递给 `DispatcherServlet` 响应客户

![img](https://oss.javaguide.cn/github/javaguide/system-design/framework/spring/de6d2b213f112297298f3e223bf08f28.png)

2.用到的设计模式：
单例（bean默认单例）、工厂（beanFactory批量创建对象）、代理（AOP）

3.统一异常处理：
 `@ControllerAdvice` + `@ExceptionHandler` 这两个注解

1）浏览器发送请求， `DispatcherServlet`拦截请求（中央处理器，接收请求，给出响应）。
2）`DispatcherServlet` 根据请求信息调用 `HandlerMapping` （ 根据 uri 去匹配查找能处理的 `Controller` ）。
3）`DispatcherServlet` 调用 `HandlerAdapter`适配执行 `Controller` 
4）`Controller` 完成对用户请求的处理后，会返回一个 `ModelAndView` 对象（包含数据和视图信息）给`DispatcherServlet`。
5）`DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
6）把 `View` 返回给请求者（浏览器）

## Spring事务

支持编程式事务（手动管理）和声明式事务（AOP `@Transactional`注解实现）。

**Spring 并不直接管理事务，而是提供了多种事务管理器** 

事务隔离级别类MySQL

# MyBatis


持久层的、轻量级的半自动化ORM框架（Object Relational Mapping对象关系映射），封装了jdbc操作，支持自定义sql、高级映射。

1.#{} 和 ${} 的区别：
`${}`是 Properties 文件中的**变量占位符**，它可以用于标签属性值和 sql 内部，属于静态文本替换
`#{}`是 sql 的**参数占位符**，MyBatis 会将 sql 中的`#{}`替换为? 号

2.Dao 接口里的方法可以重载，但是 Mybatis 的 xml 里面的 ID 不允许重复（没有namespace的情况下，id不能重复；如果有namespace，那么不同namespace的id可以重复）。
XML映射文件中的标签： select、insert、update、delete 、selectKey（为不支持自增的主键生成策略标签）、sql（为 sql 片段标签）

3.Mybatis分页：MyBatis 使用 **RowBounds** 对象进行分页，它是针对 ResultSet 结果集执行的**内存分页，而非物理分页**；(2) 可以在 sql 内直接书写带有物理分页的参数来完成物理分页功能，(3) 也可以使用分页插件来完成物理分页。
分页插件的基本原理：使用 MyBatis 提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 sql，然后重写 sql，根据 dialect 方言，**添加对应的物理分页语句和物理分页参数**。

举例： `select _ from student` ，拦截 sql 后重写为： `select t._ from （select \* from student）t limit 0，10`

4.执行批量插入，能否返回数据库主键列表：当然可以，jdbc都可以

5.动态sql：让我们在 xml 映射文件内，以标签的形式编写动态 sql，使用 OGNL 从 sql 参数对象中**计算表达式的值**，完成逻辑判断和动态拼接 sql 的功能。

6.如何将 sql 执行结果封装为目标对象并返回：
当列名和封装查询结果的类的属性名对应时，mybatis自动映射，将查询结果封装到resultType指定的对象中；
当列名和查询结果不对应时，使用 `<resultMap>` 标签，逐一定义列名和对象属性名之间的映射关系；或者使用 sql 列的别名功能，将列别名作为属性名，做到映射。
有了列名与属性名的映射关系后，MyBatis 通过**反射创建对象**，同时**使用反射给对象的属性逐一赋值**并返回，那些找不到映射关系的属性，是无法完成赋值的。

7.关联查询：可以执行一对一、一对多、多对一、多对多，使用join操作

8.延迟加载（懒加载）：仅支持一对一（association 关联对象）和一对多（collection关联对象）的延迟加载：调用 `a.getB().getName()` ，拦截器 `invoke()` 方法发现 `a.getB()` 是 null 值，就会单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上来，然后调用 a.setB(b)，接着完成 `a.getB().getName()` 方法的调用。

9.执行批处理：使用 `BatchExecutor` 完成批处理

10.三种Executor执行器：（都严格限制在 SqlSession 生命周期范围内）
`SimpleExecutor`： 每执行一次 update 或 select，就开启一个 Statement 对象，用完**立刻关闭** Statement 对象
`ReuseExecutor`： update 或 select用完后，放置于 Map<String, Statement>内，就是**重复使用** Statement 对象。
`BatchExecutor` ：执行 update（没有 select，JDBC 批处理不支持 select），将所有 sql 都添加到**批处理**中（addBatch()），缓存了多个 Statement 对象，等待统一执行（executeBatch()），与 JDBC 批处理相同。

11.MyBatis 可以映射**任何对象**到表的一列上：
映射方式为自定义一个 `TypeHandler` ，实现 `TypeHandler` 的 `setParameter()` 和 `getResult()` 接口方法。

12.MyBatis 的 xml 映射文件和 MyBatis 内部数据结构之间的映射关系：
MyBatis 将所有 xml 配置信息都封装到 All-In-One 重量级对象 Configuration 内部。在 xml 映射文件中， `<parameterMap>` 标签会被解析为 `ParameterMap` 对象，其每个子元素会被解析为 ParameterMapping 对象。 `<resultMap>` 标签会被解析为 `ResultMap` 对象，其每个子元素会被解析为 `ResultMapping` 对象。每一个 `<select>、<insert>、<update>、<delete>` 标签均会被解析为 `MappedStatement` 对象，标签内的 sql 会被解析为 BoundSql 对象。

13.半自动 vs 全自动：Hibernate 属于全自动 ORM 映射工具，使用 Hibernate 查询关联对象或者关联集合对象时，可以根据**对象关系模型**直接获取，所以它是全自动的。而 MyBatis 在查询关联对象或关联集合对象时，需要**手动编写 sql** 来完成，所以，称之为半自动 ORM 映射工具。

# Druid 

针对**海量数据实时分析**的OLAP引擎，拥有丰富的查询能力，支持**时间序列**查询、TopN查询，groupBy查询，提供API和SQL的查询方式，主要是API。

OLAP VS OLTP：OLTP（On-line Transaction Processing）针对传统SQL数据库的日常事务处理。OLAP（analyze）分析引擎。查询效率比前者低，以维度模型存储同质历史数据。

海量数据亚秒级分析响应、端到端实时（⼊库、预聚合、查询）。适合带时间维度、海量数据的实时、准实时分析，比如点击流分析、网络流量分析。

## 架构

预聚合：分析必须有预聚合，预聚合前，druid要求数据可分为：timestamp，dimension列（产品，地域，名称），metric列（数字度量）

列式存储

多级分区 位图索引

# RabbitMQ

消息队列中间件，在分布式系统中存储转发消息，可靠性，高可用性，支持多语言、多协议。

| 特点         | 描述                                           |
| ------------ | ---------------------------------------------- |
| 可靠性       | 如持久化、传输确认、发布确认                   |
| 高可用性     | 队列镜像，在部分节点出问题的情况下队列仍然可用 |
| 多语言客户端 | 支持几乎所有语言，java net                     |
| 多种协议     | 多种消息协议，STOMP、MQTT                      |
| 跟踪机制     | 消息异常时可以跟踪                             |
| 插件机制     | 可扩展                                         |

![image-20230504143032553](https://gitee.com/ziye1005/test-typora/raw/master/imgTypora/image-20230504143032553.png)

message：不透明的，包括消息头和消息体。
发送消息的应用程序（publisher），将消息发给交换器（exchange）:arrow_right:交换器将消息路由给服务器中的队列，:arrow_right:通过binding将exchange和queue进行关联:arrow_right:消息队列queue用来保存消息直到发给消费者，queue是消息的容器，也是消息的终点。一个消息可以进入多个队列:arrow_right:connection建立一个TCP/UDP连接，建立全双工通道:arrow_right:接收消息的应用程序（consumer）从消息队列中取得信息。

exchange的策略（交换器将消息交给队列的策略）：

| 消息分发策略 | 描述                                                         |
| ------------ | ------------------------------------------------------------ |
| Direct       | 完全匹配、单播模式：要求消息中的路由键（routing key）和 Binding 中的 binding key |
| Fanout       | 广播分发：到达 fanout的消息会分到**所有**绑定的队列上去，类似子网广播 |
| topic 交换器 | 模式匹配：用通配符匹配                                       |



# ETL 

ETL（Extract-Transform-Load提取转化加载）的输入是各种数据源，输出是表和数据文件，它直接决定了数据的易用性、质量、完整性、可用性。将多源异构（结构化、半结构化、非结构化）、标准不统一的数据，整合到一起，形成企业级数据仓库。

## 数据抽取

根据数据源，选择合适的抽取方式

| 数据源                                                     | 数据抽取                       |
| ---------------------------------------------------------- | ------------------------------ |
| 关系型数据库                                               | 离线抽取和实时抽取             |
| 服务器日志文件                                             | 数据量大，过滤抽取             |
| 客户端日志文件                                             | 设计一个数据收集系统来收集数据 |
| NoSQL数据库、人工整理的数据（例如Excel）、消息队列中的数据 |                                |

## 数据转换

核心环节，将抽取到的各种数据，进行数据清洗、格式转换、缺失值填补、剔除重复、增加必要信息等操作，最终得到一份格式统一、高度结构化、数据质量高、兼容性好的数据。

## 数据加载 

把数据加载到数据仓库，将处理好的数据写成特定格式（如parquet、csv等），把文件挂载到指定的表分区上。

# NoSQL基础

NoSQL（Not Only SQL 的缩写）泛指非关系型的数据库，主要针对的是键值、文档以及图形类型数据存储。并且，NoSQL 数据库天生支持**分布式，数据冗余和数据分片**等特性。NoSQL 数据库**可以存储关系型数据**，它们与关系型数据库的存储方式不同。

NoSQL 数据库代表：HBase 、Cassandra、MongoDB、Redis、Neo4j。

优势：灵活性，可扩展性（分片），高性能（大量数据），丰富API

|              | SQL 数据库                                                   | NoSQL 数据库                                                 |
| :----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 数据存储模型 | 结构化存储，具有固定行和列的表格                             | 非结构化存储。文档JSON，keyValue，图（节点和边）             |
| 例子         | Oracle、MySQL、Microsoft SQL Server 、PostgreSQL             | 文档：MongoDB、CouchDB，<br />键值：Redis 、DynamoDB，<br />宽列：Cassandra 、 HBase，非常适合需要存储大量的数据<br />图表：Neo4j 、 Giraph，知识图形化，推荐引擎 |
| ACID 属性    | 提供原子性、一致性、隔离性和持久性 (ACID) 属性               | 通常不支持 ACID 事务，为了可扩展、高性能进行了权衡，少部分支持比如 MongoDB 。不过，MongoDB 对 ACID 事务 的支持和 MySQL 还是有所区别的。 |
| 性能         | 性能通常取决于磁盘子系统。要获得最佳性能，通常需要**优化查询、索引和表结构**。 | 性能通常由底层硬件集群大小、网络延迟以及调用应用程序来决定。 |
| 扩展         | 垂直（使用性能更强大的服务器进行扩展）、读写分离、分库分表   | 横向（增加服务器的方式横向扩展，通常是基于**分片**机制）     |
| 用途         | 普通企业级的项目的数据存储                                   | 用途广泛比如图数据库支持分析和遍历连接数据之间的关系、键值数据库可以处理大量数据扩展和极高的状态变化 |
| 查询语法     | 结构化查询语言 (SQL)                                         | 数据访问语法可能因数据库而异                                 |

# Git

| github指令    | 含义                                                         |
| ------------- | ------------------------------------------------------------ |
| merge         | 等同于一次commit，有冲突判断规则，可以选择文件接受自己的，还是接受其他人的 |
| reset         | 版本回退，可以选择hard放弃本次所有的修改，工作区暂存区都清空回退 |
| rebase        | 变基，改变当前分支的起点，本地有多个commit，想合并成一个commit |
| revert        | 撤销某次`commit`                                             |
| stash         | git stash是把工作区修改的内容存储在栈区.，解决冲突文件时使用 |
| fetch vs pull | fetch时拉取远程分支；pull= fetch+merge                       |
| remote add    | 将本地推向一个远程空仓库：git remote add origin XXXX         |

